{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries (remember openai) and reference the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "df = pd.read_csv('chemistry.csv')  # Replace 'your_file.csv' with the path to your CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the openai's api for ai to summarize the transcripts and create questions based off of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # You can use any model suited for summarization\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are the master at summarizing\"},\n",
    "            {\"role\": \"user\", \"content\": \"Sumarize this transcript\" + transcript}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary\n",
    "\n",
    "# Function to get questions based on the transcript\n",
    "def get_questions(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # You can use any model suited for question generation\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are the master at giving questions\"},\n",
    "            {\"role\": \"user\", \"content\": \"Make 2 questions based on this transcript: \" + transcript}\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    questions = response.choices[0].message.content\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 3 of the summaries and each of their questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for index, row in df.iterrows():\n",
    "    title = row['Title']\n",
    "    transcript = row['Transcript']\n",
    "    \n",
    "    print(f\"Processing: {title}\\n\")\n",
    "    \n",
    "    # Get summary and questions\n",
    "    summary = get_summary(transcript)\n",
    "    questions = get_questions(transcript)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Summary:\")\n",
    "    print(summary)\n",
    "    print(\"\\nQuestions:\")\n",
    "    print(questions)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    counter += 1\n",
    "    if counter > 3:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
